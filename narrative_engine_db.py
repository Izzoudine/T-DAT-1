import json
import time
import os
import itertools
import psycopg2
import psycopg2.extras
from collections import defaultdict
from kafka import KafkaProducer
import google.generativeai as genai
from google.api_core.exceptions import ResourceExhausted
from dotenv import load_dotenv

# --- 1. CHARGEMENT SECRETS ---
load_dotenv()

# ClÃ©s API Gemini (sÃ©parÃ©es par des virgules dans le .env)
keys_str = os.getenv("GEMINI_API_KEYS")
if not keys_str:
    print("âŒ Erreur: GEMINI_API_KEYS manquant dans .env")
    exit()

API_KEYS = keys_str.split(',')
key_iterator = itertools.cycle(API_KEYS)

def switch_api_key():
    """Rotation automatique des clÃ©s API"""
    try:
        new_key = next(key_iterator)
        genai.configure(api_key=new_key)
        print(f"ğŸ”‘ Gemini Key Active: ...{new_key[-4:]}")
    except Exception as e:
        print(f"âš ï¸ Erreur Key: {e}")

# Initialisation
switch_api_key()
model = genai.GenerativeModel('gemini-2.5-flash')

# --- 2. CONFIG DB & KAFKA ---
DB_HOST = os.getenv('DB_HOST')
DB_PORT = os.getenv('DB_PORT')
DB_NAME = os.getenv('DB_NAME')
DB_USER = os.getenv('DB_USER')
DB_PASSWORD = os.getenv('DB_PASSWORD')

KAFKA_SERVER = os.getenv('KAFKA_BROKER')
OUTPUT_TOPIC = 'narrative-events' # C'est ici qu'on remplit le topic !

# ParamÃ¨tres
POLL_INTERVAL = 60  # VÃ©rifie les news toutes les minutes
MIN_ARTICLES = 2    # Il faut 2 articles pour crÃ©er un Ã©vÃ©nement (sauf urgence)

# Producer Kafka (Pour envoyer le rÃ©sultat)
producer = KafkaProducer(
    bootstrap_servers=KAFKA_SERVER,
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

def get_db_connection():
    return psycopg2.connect(
        host=DB_HOST, port=DB_PORT, dbname=DB_NAME, user=DB_USER, password=DB_PASSWORD
    )

def get_gemini_summary(articles, crypto, category):
    """Appelle l'IA pour rÃ©sumer"""
    titles = [f"- {a['title']}" for a in articles]
    titles_text = "\n".join(titles)
    
    prompt = f"""
    Role: Senior Crypto Analyst.
    Task: Analyze these headlines about {crypto} ({category}).
    Output: Write ONE single, powerful sentence (max 15 words) explaining exactly what is driving the market. No intro.
    Headlines:
    {titles_text}
    """
    
    for _ in range(3): # 3 Essais en cas d'erreur
        try:
            response = model.generate_content(prompt)
            return response.text.strip()
        except ResourceExhausted:
            print("âš ï¸ Quota dÃ©passÃ©, changement de clÃ©...")
            switch_api_key()
            time.sleep(2)
        except Exception as e:
            print(f"âš ï¸ Gemini Error: {e}")
            return f"Significant market movement detected on {crypto}."
            
    return f"Multiple reports concerning {crypto}."

def process_batch():
    """Le coeur du rÃ©acteur"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)
        
        # A. On cherche les articles NON traitÃ©s
        # On trie par date pour traiter les plus vieux d'abord
        cursor.execute("""
            SELECT * FROM articles 
            WHERE ai_processed = FALSE 
            ORDER BY datetime ASC 
            LIMIT 50
        """)
        rows = cursor.fetchall()
        
        if not rows:
            # Rien Ã  faire, on dort
            return

        print(f"ğŸ”„ Traitement IA de {len(rows)} nouveaux articles...")
        
        # B. On les regroupe (Clustering)
        # ClÃ© du groupe = (Crypto, Narratif)
        clusters = defaultdict(list)
        processed_ids = []

        for row in rows:
            processed_ids.append(row['id'])
            
            narrative = row['narrative']
            cryptos = row['cryptos'] if row['cryptos'] else [] # Peut Ãªtre None ou vide
            
            if not cryptos:
                # Si pas de crypto spÃ©cifique, c'est du MARKET global
                clusters[('MARKET', narrative)].append(row)
            else:
                # Si l'article parle de BTC et ETH, il va dans les 2 groupes
                for coin in cryptos:
                    clusters[(coin, narrative)].append(row)

        # C. Analyse IA pour chaque groupe
        events_generated = 0
        
        for key, articles in clusters.items():
            crypto, narrative = key
            
            # RÃ¨gle : SÃ©curitÃ©/RÃ©gulation = Urgent (1 article suffit)
            # Sinon il faut au moins MIN_ARTICLES
            is_urgent = narrative in ['SECURITY', 'REGULATION']
            
            if len(articles) >= MIN_ARTICLES or (is_urgent and len(articles) >= 1):
                
                # 1. GÃ©nÃ©ration du rÃ©sumÃ©
                summary = get_gemini_summary(articles, crypto, narrative)
                
                # 2. Calcul sentiment moyen
                avg_sent = sum(a['sentiment_score'] for a in articles) / len(articles)
                
                # 3. CrÃ©ation de l'Event JSON
                event = {
                    "event_id": f"evt_{int(time.time())}_{crypto}_{narrative[:3]}",
                    "timestamp": time.time(),
                    "time_str": time.strftime("%H:%M:%S"),
                    "main_crypto": crypto,
                    "narrative_category": narrative,
                    "headline": summary,
                    "sentiment_score": round(avg_sent, 3),
                    "impact_level": "HIGH" if abs(avg_sent) > 0.4 else "MEDIUM",
                    "source_count": len(articles)
                }
                
                # 4. Envoi dans Kafka (topic: narrative-events)
                producer.send(OUTPUT_TOPIC, event)
                print(f"ğŸ§  EVENT GÃ‰NÃ‰RÃ‰: [{crypto}] {summary}")
                events_generated += 1

        # D. Mise Ã  jour de la DB (On marque comme traitÃ©s)
        if processed_ids:
            cursor.execute("UPDATE articles SET ai_processed = TRUE WHERE id = ANY(%s)", (processed_ids,))
            conn.commit()
            print(f"âœ… {len(processed_ids)} articles marquÃ©s comme traitÃ©s.")
            if events_generated > 0:
                print(f"ğŸš€ {events_generated} Ã©vÃ©nements envoyÃ©s Ã  Kafka.")

    except Exception as e:
        print(f"âŒ Erreur DB/IA: {e}")
        if conn: conn.rollback()
    finally:
        if conn: conn.close()

# --- MAIN LOOP ---
print("ğŸ§  Narrative Engine (DB Mode) Started...")
print(f"ğŸ¯ Output Topic: {OUTPUT_TOPIC}")

try:
    while True:
        process_batch()
        # Pause intelligente : inutile de spammer la DB si pas de news
        time.sleep(POLL_INTERVAL) 
except KeyboardInterrupt:
    print("ArrÃªt.")
    producer.close()