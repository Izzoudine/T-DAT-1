services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Xmx512M -Xms512M"
    mem_limit: 768m
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data

  kafka:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      # Remplace l'IP ci-dessous par ton IP publique ou 127.0.0.1 si local
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://20.199.136.163:9092
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"
    mem_limit: 1.5g
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "kafka:29092"]
      interval: 10s
      timeout: 5s
      retries: 10

  spark-master:
    image: apache/spark:3.5.1
    container_name: spark-master
    user: root  # Indispensable pour pip install
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_SECRET=secret
    ports:
      - '8080:8080'
      - '7077:7077'
    volumes:
      - ./spark-jobs:/opt/spark/jobs  # <--- Note le chemin: /opt/spark
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master

  spark-worker:
    image: apache/spark:3.5.1
    container_name: spark-worker
    user: root  # Indispensable pour pip install
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
      - SPARK_RPC_AUTHENTICATION_SECRET=secret
    volumes:
      - ./spark-jobs:/opt/spark/jobs  # <--- Note le chemin: /opt/spark
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

volumes:
  kafka-data:
  zookeeper-data: